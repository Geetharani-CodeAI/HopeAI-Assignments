{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d012f52-b18a-41c7-b9ef-e3113bceb31f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in c:\\users\\hxtreme\\anaconda3\\lib\\site-packages (3.0.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\hxtreme\\anaconda3\\lib\\site-packages (from xgboost) (1.26.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\hxtreme\\anaconda3\\lib\\site-packages (from xgboost) (1.13.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ad76a0b-bc38-41e0-8902-4c52b508b167",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "021e61f4-b30e-496a-913f-dd3fd02bbcda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset=pd.read_csv(\"50_Startups.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8af34310-18d4-4c2f-a8a4-6e754695b7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State</th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>California</td>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>Florida</td>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>New York</td>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>Florida</td>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>New York</td>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>California</td>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>Florida</td>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>California</td>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>Florida</td>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>California</td>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>Florida</td>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>California</td>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>Florida</td>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>California</td>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>New York</td>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>Florida</td>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>California</td>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>New York</td>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>Florida</td>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>Florida</td>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>California</td>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>Florida</td>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>New York</td>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>Florida</td>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>New York</td>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>Florida</td>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>New York</td>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>California</td>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>Florida</td>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>California</td>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>New York</td>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>Florida</td>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>California</td>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>New York</td>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>California</td>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>California</td>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>Florida</td>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>California</td>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>New York</td>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>California</td>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>New York</td>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>Florida</td>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>California</td>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>New York</td>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>California</td>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend       State     Profit\n",
       "0   165349.20       136897.80        471784.10    New York  192261.83\n",
       "1   162597.70       151377.59        443898.53  California  191792.06\n",
       "2   153441.51       101145.55        407934.54     Florida  191050.39\n",
       "3   144372.41       118671.85        383199.62    New York  182901.99\n",
       "4   142107.34        91391.77        366168.42     Florida  166187.94\n",
       "5   131876.90        99814.71        362861.36    New York  156991.12\n",
       "6   134615.46       147198.87        127716.82  California  156122.51\n",
       "7   130298.13       145530.06        323876.68     Florida  155752.60\n",
       "8   120542.52       148718.95        311613.29    New York  152211.77\n",
       "9   123334.88       108679.17        304981.62  California  149759.96\n",
       "10  101913.08       110594.11        229160.95     Florida  146121.95\n",
       "11  100671.96        91790.61        249744.55  California  144259.40\n",
       "12   93863.75       127320.38        249839.44     Florida  141585.52\n",
       "13   91992.39       135495.07        252664.93  California  134307.35\n",
       "14  119943.24       156547.42        256512.92     Florida  132602.65\n",
       "15  114523.61       122616.84        261776.23    New York  129917.04\n",
       "16   78013.11       121597.55        264346.06  California  126992.93\n",
       "17   94657.16       145077.58        282574.31    New York  125370.37\n",
       "18   91749.16       114175.79        294919.57     Florida  124266.90\n",
       "19   86419.70       153514.11             0.00    New York  122776.86\n",
       "20   76253.86       113867.30        298664.47  California  118474.03\n",
       "21   78389.47       153773.43        299737.29    New York  111313.02\n",
       "22   73994.56       122782.75        303319.26     Florida  110352.25\n",
       "23   67532.53       105751.03        304768.73     Florida  108733.99\n",
       "24   77044.01        99281.34        140574.81    New York  108552.04\n",
       "25   64664.71       139553.16        137962.62  California  107404.34\n",
       "26   75328.87       144135.98        134050.07     Florida  105733.54\n",
       "27   72107.60       127864.55        353183.81    New York  105008.31\n",
       "28   66051.52       182645.56        118148.20     Florida  103282.38\n",
       "29   65605.48       153032.06        107138.38    New York  101004.64\n",
       "30   61994.48       115641.28         91131.24     Florida   99937.59\n",
       "31   61136.38       152701.92         88218.23    New York   97483.56\n",
       "32   63408.86       129219.61         46085.25  California   97427.84\n",
       "33   55493.95       103057.49        214634.81     Florida   96778.92\n",
       "34   46426.07       157693.92        210797.67  California   96712.80\n",
       "35   46014.02        85047.44        205517.64    New York   96479.51\n",
       "36   28663.76       127056.21        201126.82     Florida   90708.19\n",
       "37   44069.95        51283.14        197029.42  California   89949.14\n",
       "38   20229.59        65947.93        185265.10    New York   81229.06\n",
       "39   38558.51        82982.09        174999.30  California   81005.76\n",
       "40   28754.33       118546.05        172795.67  California   78239.91\n",
       "41   27892.92        84710.77        164470.71     Florida   77798.83\n",
       "42   23640.93        96189.63        148001.11  California   71498.49\n",
       "43   15505.73       127382.30         35534.17    New York   69758.98\n",
       "44   22177.74       154806.14         28334.72  California   65200.33\n",
       "45    1000.23       124153.04          1903.93    New York   64926.08\n",
       "46    1315.46       115816.21        297114.46     Florida   49490.75\n",
       "47       0.00       135426.92             0.00  California   42559.73\n",
       "48     542.05        51743.15             0.00    New York   35673.41\n",
       "49       0.00       116983.80         45173.06  California   14681.40"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6c07a3d-a5a3-4b99-b6d5-b1ddea2d8297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>Profit</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>192261.83</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>191792.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>191050.39</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>182901.99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>166187.94</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>156991.12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>156122.51</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>155752.60</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>152211.77</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>149759.96</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>146121.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>144259.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>141585.52</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>134307.35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>132602.65</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>129917.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>126992.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>125370.37</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>124266.90</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>122776.86</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>118474.03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>111313.02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>110352.25</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>108733.99</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>108552.04</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>107404.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>105733.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>105008.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>103282.38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>101004.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>99937.59</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>97483.56</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>97427.84</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>96778.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>96712.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>96479.51</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>90708.19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>89949.14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>81229.06</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>81005.76</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>78239.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>77798.83</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>71498.49</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>69758.98</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>65200.33</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>64926.08</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>49490.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>42559.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>35673.41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>14681.40</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend     Profit  State_Florida  \\\n",
       "0   165349.20       136897.80        471784.10  192261.83              0   \n",
       "1   162597.70       151377.59        443898.53  191792.06              0   \n",
       "2   153441.51       101145.55        407934.54  191050.39              1   \n",
       "3   144372.41       118671.85        383199.62  182901.99              0   \n",
       "4   142107.34        91391.77        366168.42  166187.94              1   \n",
       "5   131876.90        99814.71        362861.36  156991.12              0   \n",
       "6   134615.46       147198.87        127716.82  156122.51              0   \n",
       "7   130298.13       145530.06        323876.68  155752.60              1   \n",
       "8   120542.52       148718.95        311613.29  152211.77              0   \n",
       "9   123334.88       108679.17        304981.62  149759.96              0   \n",
       "10  101913.08       110594.11        229160.95  146121.95              1   \n",
       "11  100671.96        91790.61        249744.55  144259.40              0   \n",
       "12   93863.75       127320.38        249839.44  141585.52              1   \n",
       "13   91992.39       135495.07        252664.93  134307.35              0   \n",
       "14  119943.24       156547.42        256512.92  132602.65              1   \n",
       "15  114523.61       122616.84        261776.23  129917.04              0   \n",
       "16   78013.11       121597.55        264346.06  126992.93              0   \n",
       "17   94657.16       145077.58        282574.31  125370.37              0   \n",
       "18   91749.16       114175.79        294919.57  124266.90              1   \n",
       "19   86419.70       153514.11             0.00  122776.86              0   \n",
       "20   76253.86       113867.30        298664.47  118474.03              0   \n",
       "21   78389.47       153773.43        299737.29  111313.02              0   \n",
       "22   73994.56       122782.75        303319.26  110352.25              1   \n",
       "23   67532.53       105751.03        304768.73  108733.99              1   \n",
       "24   77044.01        99281.34        140574.81  108552.04              0   \n",
       "25   64664.71       139553.16        137962.62  107404.34              0   \n",
       "26   75328.87       144135.98        134050.07  105733.54              1   \n",
       "27   72107.60       127864.55        353183.81  105008.31              0   \n",
       "28   66051.52       182645.56        118148.20  103282.38              1   \n",
       "29   65605.48       153032.06        107138.38  101004.64              0   \n",
       "30   61994.48       115641.28         91131.24   99937.59              1   \n",
       "31   61136.38       152701.92         88218.23   97483.56              0   \n",
       "32   63408.86       129219.61         46085.25   97427.84              0   \n",
       "33   55493.95       103057.49        214634.81   96778.92              1   \n",
       "34   46426.07       157693.92        210797.67   96712.80              0   \n",
       "35   46014.02        85047.44        205517.64   96479.51              0   \n",
       "36   28663.76       127056.21        201126.82   90708.19              1   \n",
       "37   44069.95        51283.14        197029.42   89949.14              0   \n",
       "38   20229.59        65947.93        185265.10   81229.06              0   \n",
       "39   38558.51        82982.09        174999.30   81005.76              0   \n",
       "40   28754.33       118546.05        172795.67   78239.91              0   \n",
       "41   27892.92        84710.77        164470.71   77798.83              1   \n",
       "42   23640.93        96189.63        148001.11   71498.49              0   \n",
       "43   15505.73       127382.30         35534.17   69758.98              0   \n",
       "44   22177.74       154806.14         28334.72   65200.33              0   \n",
       "45    1000.23       124153.04          1903.93   64926.08              0   \n",
       "46    1315.46       115816.21        297114.46   49490.75              1   \n",
       "47       0.00       135426.92             0.00   42559.73              0   \n",
       "48     542.05        51743.15             0.00   35673.41              0   \n",
       "49       0.00       116983.80         45173.06   14681.40              0   \n",
       "\n",
       "    State_New York  \n",
       "0                1  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                0  \n",
       "5                1  \n",
       "6                0  \n",
       "7                0  \n",
       "8                1  \n",
       "9                0  \n",
       "10               0  \n",
       "11               0  \n",
       "12               0  \n",
       "13               0  \n",
       "14               0  \n",
       "15               1  \n",
       "16               0  \n",
       "17               1  \n",
       "18               0  \n",
       "19               1  \n",
       "20               0  \n",
       "21               1  \n",
       "22               0  \n",
       "23               0  \n",
       "24               1  \n",
       "25               0  \n",
       "26               0  \n",
       "27               1  \n",
       "28               0  \n",
       "29               1  \n",
       "30               0  \n",
       "31               1  \n",
       "32               0  \n",
       "33               0  \n",
       "34               0  \n",
       "35               1  \n",
       "36               0  \n",
       "37               0  \n",
       "38               1  \n",
       "39               0  \n",
       "40               0  \n",
       "41               0  \n",
       "42               0  \n",
       "43               1  \n",
       "44               0  \n",
       "45               1  \n",
       "46               0  \n",
       "47               0  \n",
       "48               1  \n",
       "49               0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset=pd.get_dummies(dataset,dtype=int,drop_first=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dbc8ff4-ff62-49b6-9f67-256ba117efcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['R&D Spend', 'Administration', 'Marketing Spend', 'Profit',\n",
       "       'State_Florida', 'State_New York'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16d155c7-3bda-41fe-b751-18409aaad10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R&amp;D Spend</th>\n",
       "      <th>Administration</th>\n",
       "      <th>Marketing Spend</th>\n",
       "      <th>State_Florida</th>\n",
       "      <th>State_New York</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>165349.20</td>\n",
       "      <td>136897.80</td>\n",
       "      <td>471784.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>162597.70</td>\n",
       "      <td>151377.59</td>\n",
       "      <td>443898.53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>153441.51</td>\n",
       "      <td>101145.55</td>\n",
       "      <td>407934.54</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>144372.41</td>\n",
       "      <td>118671.85</td>\n",
       "      <td>383199.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142107.34</td>\n",
       "      <td>91391.77</td>\n",
       "      <td>366168.42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>131876.90</td>\n",
       "      <td>99814.71</td>\n",
       "      <td>362861.36</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>134615.46</td>\n",
       "      <td>147198.87</td>\n",
       "      <td>127716.82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>130298.13</td>\n",
       "      <td>145530.06</td>\n",
       "      <td>323876.68</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120542.52</td>\n",
       "      <td>148718.95</td>\n",
       "      <td>311613.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>123334.88</td>\n",
       "      <td>108679.17</td>\n",
       "      <td>304981.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>101913.08</td>\n",
       "      <td>110594.11</td>\n",
       "      <td>229160.95</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>100671.96</td>\n",
       "      <td>91790.61</td>\n",
       "      <td>249744.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>93863.75</td>\n",
       "      <td>127320.38</td>\n",
       "      <td>249839.44</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>91992.39</td>\n",
       "      <td>135495.07</td>\n",
       "      <td>252664.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>119943.24</td>\n",
       "      <td>156547.42</td>\n",
       "      <td>256512.92</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114523.61</td>\n",
       "      <td>122616.84</td>\n",
       "      <td>261776.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>78013.11</td>\n",
       "      <td>121597.55</td>\n",
       "      <td>264346.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94657.16</td>\n",
       "      <td>145077.58</td>\n",
       "      <td>282574.31</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>91749.16</td>\n",
       "      <td>114175.79</td>\n",
       "      <td>294919.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>86419.70</td>\n",
       "      <td>153514.11</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>76253.86</td>\n",
       "      <td>113867.30</td>\n",
       "      <td>298664.47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>78389.47</td>\n",
       "      <td>153773.43</td>\n",
       "      <td>299737.29</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>73994.56</td>\n",
       "      <td>122782.75</td>\n",
       "      <td>303319.26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>67532.53</td>\n",
       "      <td>105751.03</td>\n",
       "      <td>304768.73</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>77044.01</td>\n",
       "      <td>99281.34</td>\n",
       "      <td>140574.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>64664.71</td>\n",
       "      <td>139553.16</td>\n",
       "      <td>137962.62</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>75328.87</td>\n",
       "      <td>144135.98</td>\n",
       "      <td>134050.07</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>72107.60</td>\n",
       "      <td>127864.55</td>\n",
       "      <td>353183.81</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>66051.52</td>\n",
       "      <td>182645.56</td>\n",
       "      <td>118148.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>65605.48</td>\n",
       "      <td>153032.06</td>\n",
       "      <td>107138.38</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>61994.48</td>\n",
       "      <td>115641.28</td>\n",
       "      <td>91131.24</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>61136.38</td>\n",
       "      <td>152701.92</td>\n",
       "      <td>88218.23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>63408.86</td>\n",
       "      <td>129219.61</td>\n",
       "      <td>46085.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>55493.95</td>\n",
       "      <td>103057.49</td>\n",
       "      <td>214634.81</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>46426.07</td>\n",
       "      <td>157693.92</td>\n",
       "      <td>210797.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>46014.02</td>\n",
       "      <td>85047.44</td>\n",
       "      <td>205517.64</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>28663.76</td>\n",
       "      <td>127056.21</td>\n",
       "      <td>201126.82</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>44069.95</td>\n",
       "      <td>51283.14</td>\n",
       "      <td>197029.42</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20229.59</td>\n",
       "      <td>65947.93</td>\n",
       "      <td>185265.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>38558.51</td>\n",
       "      <td>82982.09</td>\n",
       "      <td>174999.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>28754.33</td>\n",
       "      <td>118546.05</td>\n",
       "      <td>172795.67</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>27892.92</td>\n",
       "      <td>84710.77</td>\n",
       "      <td>164470.71</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>23640.93</td>\n",
       "      <td>96189.63</td>\n",
       "      <td>148001.11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>15505.73</td>\n",
       "      <td>127382.30</td>\n",
       "      <td>35534.17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>22177.74</td>\n",
       "      <td>154806.14</td>\n",
       "      <td>28334.72</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1000.23</td>\n",
       "      <td>124153.04</td>\n",
       "      <td>1903.93</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1315.46</td>\n",
       "      <td>115816.21</td>\n",
       "      <td>297114.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.00</td>\n",
       "      <td>135426.92</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>542.05</td>\n",
       "      <td>51743.15</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.00</td>\n",
       "      <td>116983.80</td>\n",
       "      <td>45173.06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    R&D Spend  Administration  Marketing Spend  State_Florida  State_New York\n",
       "0   165349.20       136897.80        471784.10              0               1\n",
       "1   162597.70       151377.59        443898.53              0               0\n",
       "2   153441.51       101145.55        407934.54              1               0\n",
       "3   144372.41       118671.85        383199.62              0               1\n",
       "4   142107.34        91391.77        366168.42              1               0\n",
       "5   131876.90        99814.71        362861.36              0               1\n",
       "6   134615.46       147198.87        127716.82              0               0\n",
       "7   130298.13       145530.06        323876.68              1               0\n",
       "8   120542.52       148718.95        311613.29              0               1\n",
       "9   123334.88       108679.17        304981.62              0               0\n",
       "10  101913.08       110594.11        229160.95              1               0\n",
       "11  100671.96        91790.61        249744.55              0               0\n",
       "12   93863.75       127320.38        249839.44              1               0\n",
       "13   91992.39       135495.07        252664.93              0               0\n",
       "14  119943.24       156547.42        256512.92              1               0\n",
       "15  114523.61       122616.84        261776.23              0               1\n",
       "16   78013.11       121597.55        264346.06              0               0\n",
       "17   94657.16       145077.58        282574.31              0               1\n",
       "18   91749.16       114175.79        294919.57              1               0\n",
       "19   86419.70       153514.11             0.00              0               1\n",
       "20   76253.86       113867.30        298664.47              0               0\n",
       "21   78389.47       153773.43        299737.29              0               1\n",
       "22   73994.56       122782.75        303319.26              1               0\n",
       "23   67532.53       105751.03        304768.73              1               0\n",
       "24   77044.01        99281.34        140574.81              0               1\n",
       "25   64664.71       139553.16        137962.62              0               0\n",
       "26   75328.87       144135.98        134050.07              1               0\n",
       "27   72107.60       127864.55        353183.81              0               1\n",
       "28   66051.52       182645.56        118148.20              1               0\n",
       "29   65605.48       153032.06        107138.38              0               1\n",
       "30   61994.48       115641.28         91131.24              1               0\n",
       "31   61136.38       152701.92         88218.23              0               1\n",
       "32   63408.86       129219.61         46085.25              0               0\n",
       "33   55493.95       103057.49        214634.81              1               0\n",
       "34   46426.07       157693.92        210797.67              0               0\n",
       "35   46014.02        85047.44        205517.64              0               1\n",
       "36   28663.76       127056.21        201126.82              1               0\n",
       "37   44069.95        51283.14        197029.42              0               0\n",
       "38   20229.59        65947.93        185265.10              0               1\n",
       "39   38558.51        82982.09        174999.30              0               0\n",
       "40   28754.33       118546.05        172795.67              0               0\n",
       "41   27892.92        84710.77        164470.71              1               0\n",
       "42   23640.93        96189.63        148001.11              0               0\n",
       "43   15505.73       127382.30         35534.17              0               1\n",
       "44   22177.74       154806.14         28334.72              0               0\n",
       "45    1000.23       124153.04          1903.93              0               1\n",
       "46    1315.46       115816.21        297114.46              1               0\n",
       "47       0.00       135426.92             0.00              0               0\n",
       "48     542.05        51743.15             0.00              0               1\n",
       "49       0.00       116983.80         45173.06              0               0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent=dataset[['R&D Spend', 'Administration', 'Marketing Spend', 'State_Florida', 'State_New York']]\n",
    "independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69b689fa-ff4f-4ca9-ab11-03b8f83439b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Profit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192261.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>191792.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>191050.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>182901.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>166187.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>156991.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>156122.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>155752.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>152211.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>149759.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>146121.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>144259.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>141585.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>134307.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>132602.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>129917.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>126992.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>125370.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>124266.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>122776.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>118474.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>111313.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>110352.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>108733.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>108552.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107404.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>105733.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>105008.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>103282.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>101004.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>99937.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>97483.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>97427.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>96778.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>96712.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>96479.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>90708.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>89949.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>81229.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>81005.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>78239.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>77798.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>71498.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>69758.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>65200.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>64926.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>49490.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>42559.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>35673.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>14681.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Profit\n",
       "0   192261.83\n",
       "1   191792.06\n",
       "2   191050.39\n",
       "3   182901.99\n",
       "4   166187.94\n",
       "5   156991.12\n",
       "6   156122.51\n",
       "7   155752.60\n",
       "8   152211.77\n",
       "9   149759.96\n",
       "10  146121.95\n",
       "11  144259.40\n",
       "12  141585.52\n",
       "13  134307.35\n",
       "14  132602.65\n",
       "15  129917.04\n",
       "16  126992.93\n",
       "17  125370.37\n",
       "18  124266.90\n",
       "19  122776.86\n",
       "20  118474.03\n",
       "21  111313.02\n",
       "22  110352.25\n",
       "23  108733.99\n",
       "24  108552.04\n",
       "25  107404.34\n",
       "26  105733.54\n",
       "27  105008.31\n",
       "28  103282.38\n",
       "29  101004.64\n",
       "30   99937.59\n",
       "31   97483.56\n",
       "32   97427.84\n",
       "33   96778.92\n",
       "34   96712.80\n",
       "35   96479.51\n",
       "36   90708.19\n",
       "37   89949.14\n",
       "38   81229.06\n",
       "39   81005.76\n",
       "40   78239.91\n",
       "41   77798.83\n",
       "42   71498.49\n",
       "43   69758.98\n",
       "44   65200.33\n",
       "45   64926.08\n",
       "46   49490.75\n",
       "47   42559.73\n",
       "48   35673.41\n",
       "49   14681.40"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent = dataset[['Profit']]\n",
    "dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d056733e-8a46-44eb-ae8b-07192857c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adaboost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac3873a1-7bdd-4e7c-9bc9-a86eadc27ed7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 45 candidates, totalling 225 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hxtreme\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1339: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;GridSearchCV<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.model_selection.GridSearchCV.html\">?<span>Documentation for GridSearchCV</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>GridSearchCV(estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={&#x27;learning_rate&#x27;: [0.5, 0.7, 1.0],\n",
       "                         &#x27;loss&#x27;: [&#x27;linear&#x27;, &#x27;square&#x27;, &#x27;exponential&#x27;],\n",
       "                         &#x27;n_estimators&#x27;: [10, 20, 30, 40, 50]},\n",
       "             verbose=3)</pre></div> </div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">best_estimator_: AdaBoostRegressor</label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostRegressor(learning_rate=0.7, loss=&#x27;square&#x27;)</pre></div> </div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;AdaBoostRegressor<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.ensemble.AdaBoostRegressor.html\">?<span>Documentation for AdaBoostRegressor</span></a></label><div class=\"sk-toggleable__content fitted\"><pre>AdaBoostRegressor(learning_rate=0.7, loss=&#x27;square&#x27;)</pre></div> </div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(estimator=AdaBoostRegressor(), n_jobs=-1,\n",
       "             param_grid={'learning_rate': [0.5, 0.7, 1.0],\n",
       "                         'loss': ['linear', 'square', 'exponential'],\n",
       "                         'n_estimators': [10, 20, 30, 40, 50]},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "param_grid = {'loss':['linear','square','exponential'],\n",
    "              'learning_rate':[0.5,0.7,1.0],'n_estimators':[10,20,30,40,50]}\n",
    "grid = GridSearchCV(AdaBoostRegressor(),param_grid,verbose=3,n_jobs=-1)\n",
    "grid.fit(independent,dependent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "692d1153-1004-4a59-9a53-dc2310b0b184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 50}\n",
      "{'mean_fit_time': array([0.06699638, 0.1093926 , 0.15439048, 0.22118621, 0.27798266,\n",
      "       0.05848851, 0.10050955, 0.13799109, 0.20800533, 0.2253861 ,\n",
      "       0.05640979, 0.10219398, 0.14139214, 0.18318925, 0.23658571,\n",
      "       0.05559316, 0.09979401, 0.14239078, 0.18798819, 0.22578688,\n",
      "       0.0541965 , 0.09819369, 0.14201126, 0.18278861, 0.22678652,\n",
      "       0.05382347, 0.09819388, 0.14119148, 0.18678713, 0.24218431,\n",
      "       0.05699677, 0.09959393, 0.13499193, 0.18398838, 0.22498703,\n",
      "       0.05339808, 0.10399318, 0.17358999, 0.19538755, 0.22998581,\n",
      "       0.05439706, 0.10039444, 0.14739113, 0.19038811, 0.22098665]), 'std_fit_time': array([0.00395006, 0.00382308, 0.00449727, 0.03436324, 0.03597513,\n",
      "       0.00313966, 0.00449404, 0.00334648, 0.01500212, 0.00338206,\n",
      "       0.00391501, 0.00348677, 0.00257619, 0.00292626, 0.0118419 ,\n",
      "       0.00516161, 0.00487446, 0.0033822 , 0.00583037, 0.00487547,\n",
      "       0.00444543, 0.00342893, 0.00277047, 0.00203924, 0.00503528,\n",
      "       0.0036049 , 0.00160044, 0.00305956, 0.00292561, 0.00292556,\n",
      "       0.00589919, 0.00431702, 0.02632716, 0.006033  , 0.00328665,\n",
      "       0.00195917, 0.00562119, 0.02694028, 0.010782  , 0.01082538,\n",
      "       0.00349824, 0.00205883, 0.00454288, 0.00458694, 0.00965324]), 'mean_score_time': array([0.01339836, 0.01539989, 0.0191988 , 0.02999907, 0.02661123,\n",
      "       0.0127069 , 0.0144958 , 0.01848378, 0.02098083, 0.02559843,\n",
      "       0.01238532, 0.01379881, 0.01779866, 0.02239833, 0.02539821,\n",
      "       0.0109992 , 0.01639862, 0.01899891, 0.02079897, 0.02539792,\n",
      "       0.01259909, 0.01539955, 0.01718006, 0.0229991 , 0.02581496,\n",
      "       0.01077218, 0.01479878, 0.0201993 , 0.02259889, 0.02739844,\n",
      "       0.01199918, 0.01479964, 0.01859913, 0.02219872, 0.02539811,\n",
      "       0.01139927, 0.01659894, 0.01819873, 0.02179837, 0.02479858,\n",
      "       0.01119857, 0.01519876, 0.01819954, 0.02179866, 0.02359862]), 'std_score_time': array([0.00205992, 0.00185502, 0.00146972, 0.00672276, 0.00148263,\n",
      "       0.00259112, 0.00043582, 0.00134125, 0.00091494, 0.00135638,\n",
      "       0.00103798, 0.00039976, 0.00040042, 0.00135694, 0.00135635,\n",
      "       0.00063301, 0.00195998, 0.00260736, 0.00040033, 0.00185513,\n",
      "       0.00286968, 0.00119965, 0.00041005, 0.00236666, 0.00222865,\n",
      "       0.00038718, 0.00172027, 0.00203939, 0.00224437, 0.00205896,\n",
      "       0.00109558, 0.0011657 , 0.00417576, 0.00146967, 0.0014958 ,\n",
      "       0.00048911, 0.00241658, 0.00116565, 0.00074833, 0.00040016,\n",
      "       0.00074876, 0.00098029, 0.00040014, 0.00074802, 0.00403074]), 'param_learning_rate': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5,\n",
      "                   0.5, 0.5, 0.5, 0.5, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7,\n",
      "                   0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 1.0, 1.0, 1.0,\n",
      "                   1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,\n",
      "                   1.0],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value=1e+20), 'param_loss': masked_array(data=['linear', 'linear', 'linear', 'linear', 'linear',\n",
      "                   'square', 'square', 'square', 'square', 'square',\n",
      "                   'exponential', 'exponential', 'exponential',\n",
      "                   'exponential', 'exponential', 'linear', 'linear',\n",
      "                   'linear', 'linear', 'linear', 'square', 'square',\n",
      "                   'square', 'square', 'square', 'exponential',\n",
      "                   'exponential', 'exponential', 'exponential',\n",
      "                   'exponential', 'linear', 'linear', 'linear', 'linear',\n",
      "                   'linear', 'square', 'square', 'square', 'square',\n",
      "                   'square', 'exponential', 'exponential', 'exponential',\n",
      "                   'exponential', 'exponential'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_n_estimators': masked_array(data=[10, 20, 30, 40, 50, 10, 20, 30, 40, 50, 10, 20, 30, 40,\n",
      "                   50, 10, 20, 30, 40, 50, 10, 20, 30, 40, 50, 10, 20, 30,\n",
      "                   40, 50, 10, 20, 30, 40, 50, 10, 20, 30, 40, 50, 10, 20,\n",
      "                   30, 40, 50],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False],\n",
      "       fill_value=999999), 'params': [{'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 10}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 20}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 30}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 40}, {'learning_rate': 0.5, 'loss': 'linear', 'n_estimators': 50}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 10}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 20}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 30}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 40}, {'learning_rate': 0.5, 'loss': 'square', 'n_estimators': 50}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 10}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 20}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 30}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 40}, {'learning_rate': 0.5, 'loss': 'exponential', 'n_estimators': 50}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 10}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 20}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 30}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 40}, {'learning_rate': 0.7, 'loss': 'linear', 'n_estimators': 50}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 10}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 20}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 30}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 40}, {'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 50}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 10}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 20}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 30}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 40}, {'learning_rate': 0.7, 'loss': 'exponential', 'n_estimators': 50}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 10}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 20}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 30}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 40}, {'learning_rate': 1.0, 'loss': 'linear', 'n_estimators': 50}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 10}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 20}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 30}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 40}, {'learning_rate': 1.0, 'loss': 'square', 'n_estimators': 50}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 10}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 20}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 30}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 40}, {'learning_rate': 1.0, 'loss': 'exponential', 'n_estimators': 50}], 'split0_test_score': array([0.81202779, 0.84480393, 0.85367459, 0.84886549, 0.85761603,\n",
      "       0.86989774, 0.83526512, 0.84822703, 0.82966144, 0.86529729,\n",
      "       0.8669281 , 0.8449461 , 0.85574641, 0.84463121, 0.84709014,\n",
      "       0.87463382, 0.82004103, 0.82865124, 0.8535255 , 0.84479441,\n",
      "       0.82670451, 0.83859015, 0.85581493, 0.85976496, 0.86402906,\n",
      "       0.86716423, 0.74262466, 0.82295705, 0.89583867, 0.8549579 ,\n",
      "       0.74037645, 0.79617125, 0.7898003 , 0.83866545, 0.851792  ,\n",
      "       0.76714636, 0.85815906, 0.85256331, 0.87699782, 0.81035287,\n",
      "       0.84230775, 0.82589612, 0.86682449, 0.85095415, 0.85374922]), 'split1_test_score': array([0.83141058, 0.85337748, 0.87068633, 0.84564979, 0.84794901,\n",
      "       0.83222673, 0.86490273, 0.85720115, 0.87110076, 0.86223973,\n",
      "       0.83040624, 0.8383082 , 0.84298837, 0.84980034, 0.85693528,\n",
      "       0.85570802, 0.84302182, 0.85605907, 0.85542732, 0.84774617,\n",
      "       0.82713769, 0.84057619, 0.86154173, 0.89901165, 0.85946256,\n",
      "       0.90378588, 0.86490596, 0.84706336, 0.8538608 , 0.8517938 ,\n",
      "       0.8544529 , 0.84704916, 0.86162669, 0.85132916, 0.87010204,\n",
      "       0.87952472, 0.8778262 , 0.88723985, 0.88091171, 0.88554953,\n",
      "       0.82301232, 0.89471943, 0.85840491, 0.86129718, 0.86199992]), 'split2_test_score': array([0.94256539, 0.8683028 , 0.92061955, 0.92400327, 0.88270177,\n",
      "       0.92859226, 0.89464892, 0.88718016, 0.93540286, 0.92419389,\n",
      "       0.85359115, 0.92844493, 0.94511879, 0.93254646, 0.89481239,\n",
      "       0.93702712, 0.92754762, 0.93746001, 0.89747512, 0.93125238,\n",
      "       0.90194631, 0.90477957, 0.93379507, 0.93903896, 0.92591978,\n",
      "       0.91375723, 0.88064201, 0.92240604, 0.91162744, 0.92645002,\n",
      "       0.93224143, 0.93541544, 0.92245469, 0.93152163, 0.93042311,\n",
      "       0.85842734, 0.89006444, 0.9386594 , 0.91814273, 0.91997247,\n",
      "       0.93146507, 0.90163175, 0.91827876, 0.88408532, 0.93056502]), 'split3_test_score': array([0.25448692, 0.51032143, 0.62749059, 0.505331  , 0.65220059,\n",
      "       0.36192703, 0.5516661 , 0.72811356, 0.62121346, 0.61242657,\n",
      "       0.60060613, 0.56710721, 0.49022583, 0.66508564, 0.67899834,\n",
      "       0.44614335, 0.68315022, 0.7933531 , 0.65556941, 0.48310969,\n",
      "       0.57244916, 0.62933428, 0.47748249, 0.68640373, 0.76590089,\n",
      "       0.60957572, 0.64023966, 0.63586333, 0.63982335, 0.7045244 ,\n",
      "       0.69621741, 0.69103869, 0.69919415, 0.61005592, 0.74530919,\n",
      "       0.71305661, 0.69877979, 0.71383581, 0.57785416, 0.57705572,\n",
      "       0.52907205, 0.65261142, 0.72032931, 0.62696599, 0.64752613]), 'split4_test_score': array([0.87115933, 0.91773054, 0.91455602, 0.91637639, 0.94277584,\n",
      "       0.94019747, 0.91110709, 0.91753525, 0.91964624, 0.92120668,\n",
      "       0.882484  , 0.88893969, 0.95129921, 0.93896695, 0.91712448,\n",
      "       0.86149414, 0.8682229 , 0.8958206 , 0.93909482, 0.93539296,\n",
      "       0.91457565, 0.90550808, 0.9182169 , 0.91432041, 0.92403241,\n",
      "       0.9272847 , 0.94118683, 0.91544763, 0.89555207, 0.94964763,\n",
      "       0.91831419, 0.9446234 , 0.91435563, 0.94786839, 0.91770291,\n",
      "       0.95164418, 0.94767257, 0.92294693, 0.91834473, 0.95644849,\n",
      "       0.88775006, 0.9269009 , 0.9396119 , 0.94514723, 0.94682532]), 'mean_test_score': array([0.74233   , 0.79890724, 0.83740541, 0.80804519, 0.83664865,\n",
      "       0.78656825, 0.81151799, 0.84765143, 0.83540495, 0.83707283,\n",
      "       0.80680312, 0.81354923, 0.81707572, 0.84620612, 0.83899213,\n",
      "       0.79500129, 0.82839672, 0.8622688 , 0.84021843, 0.80845912,\n",
      "       0.80856266, 0.82375766, 0.80937022, 0.85970794, 0.86786894,\n",
      "       0.84431355, 0.81391982, 0.82874748, 0.83934047, 0.85747475,\n",
      "       0.82832047, 0.84285959, 0.83748629, 0.83588811, 0.86306585,\n",
      "       0.83395984, 0.85450041, 0.86304906, 0.83445023, 0.82987582,\n",
      "       0.80272145, 0.84035193, 0.86068987, 0.83368998, 0.84813312]), 'std_test_score': array([0.24798194, 0.1464855 , 0.10799384, 0.15485361, 0.0979513 ,\n",
      "       0.21592657, 0.13248819, 0.06454007, 0.11338549, 0.11538156,\n",
      "       0.10450458, 0.12744974, 0.16935685, 0.0988729 , 0.083912  ,\n",
      "       0.17681694, 0.08099047, 0.05039349, 0.09752796, 0.16727603,\n",
      "       0.12359855, 0.10153915, 0.16873505, 0.09039366, 0.05832174,\n",
      "       0.11905259, 0.10816296, 0.10379031, 0.10158259, 0.08565728,\n",
      "       0.0946221 , 0.09398872, 0.08379732, 0.1207739 , 0.06567412,\n",
      "       0.08438726, 0.08336935, 0.08032984, 0.12950153, 0.13530466,\n",
      "       0.14189261, 0.09965665, 0.07653641, 0.10840427, 0.10677281]), 'rank_test_score': array([45, 42, 19, 39, 21, 44, 35, 10, 23, 20, 40, 34, 32, 11, 17, 43, 29,\n",
      "        4, 15, 38, 37, 31, 36,  6,  1, 12, 33, 28, 16,  7, 30, 13, 18, 22,\n",
      "        2, 25,  8,  3, 24, 27, 41, 14,  5, 26,  9])}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)\n",
    "re=grid.cv_results_\n",
    "print(re)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "134955c8-5ac7-4cc4-94fa-bb387813c94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best R_score value for Parameters:{'learning_rate': 0.7, 'loss': 'square', 'n_estimators': 50} 0.9198518588534128\n"
     ]
    }
   ],
   "source": [
    "print(\"The best R_score value Parameters:{}\".format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd67b055-c084-49c8-8f65-82314563034a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_learning_rate</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_n_estimators</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.066996</td>\n",
       "      <td>0.003950</td>\n",
       "      <td>0.013398</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.812028</td>\n",
       "      <td>0.831411</td>\n",
       "      <td>0.942565</td>\n",
       "      <td>0.254487</td>\n",
       "      <td>0.871159</td>\n",
       "      <td>0.742330</td>\n",
       "      <td>0.247982</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.109393</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.844804</td>\n",
       "      <td>0.853377</td>\n",
       "      <td>0.868303</td>\n",
       "      <td>0.510321</td>\n",
       "      <td>0.917731</td>\n",
       "      <td>0.798907</td>\n",
       "      <td>0.146485</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.154390</td>\n",
       "      <td>0.004497</td>\n",
       "      <td>0.019199</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.853675</td>\n",
       "      <td>0.870686</td>\n",
       "      <td>0.920620</td>\n",
       "      <td>0.627491</td>\n",
       "      <td>0.914556</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>0.107994</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.221186</td>\n",
       "      <td>0.034363</td>\n",
       "      <td>0.029999</td>\n",
       "      <td>0.006723</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.848865</td>\n",
       "      <td>0.845650</td>\n",
       "      <td>0.924003</td>\n",
       "      <td>0.505331</td>\n",
       "      <td>0.916376</td>\n",
       "      <td>0.808045</td>\n",
       "      <td>0.154854</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.277983</td>\n",
       "      <td>0.035975</td>\n",
       "      <td>0.026611</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.5</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.857616</td>\n",
       "      <td>0.847949</td>\n",
       "      <td>0.882702</td>\n",
       "      <td>0.652201</td>\n",
       "      <td>0.942776</td>\n",
       "      <td>0.836649</td>\n",
       "      <td>0.097951</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.058489</td>\n",
       "      <td>0.003140</td>\n",
       "      <td>0.012707</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.869898</td>\n",
       "      <td>0.832227</td>\n",
       "      <td>0.928592</td>\n",
       "      <td>0.361927</td>\n",
       "      <td>0.940197</td>\n",
       "      <td>0.786568</td>\n",
       "      <td>0.215927</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.100510</td>\n",
       "      <td>0.004494</td>\n",
       "      <td>0.014496</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.835265</td>\n",
       "      <td>0.864903</td>\n",
       "      <td>0.894649</td>\n",
       "      <td>0.551666</td>\n",
       "      <td>0.911107</td>\n",
       "      <td>0.811518</td>\n",
       "      <td>0.132488</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.137991</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.018484</td>\n",
       "      <td>0.001341</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.848227</td>\n",
       "      <td>0.857201</td>\n",
       "      <td>0.887180</td>\n",
       "      <td>0.728114</td>\n",
       "      <td>0.917535</td>\n",
       "      <td>0.847651</td>\n",
       "      <td>0.064540</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.208005</td>\n",
       "      <td>0.015002</td>\n",
       "      <td>0.020981</td>\n",
       "      <td>0.000915</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.829661</td>\n",
       "      <td>0.871101</td>\n",
       "      <td>0.935403</td>\n",
       "      <td>0.621213</td>\n",
       "      <td>0.919646</td>\n",
       "      <td>0.835405</td>\n",
       "      <td>0.113385</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.225386</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.025598</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.5</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.865297</td>\n",
       "      <td>0.862240</td>\n",
       "      <td>0.924194</td>\n",
       "      <td>0.612427</td>\n",
       "      <td>0.921207</td>\n",
       "      <td>0.837073</td>\n",
       "      <td>0.115382</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.056410</td>\n",
       "      <td>0.003915</td>\n",
       "      <td>0.012385</td>\n",
       "      <td>0.001038</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>0.866928</td>\n",
       "      <td>0.830406</td>\n",
       "      <td>0.853591</td>\n",
       "      <td>0.600606</td>\n",
       "      <td>0.882484</td>\n",
       "      <td>0.806803</td>\n",
       "      <td>0.104505</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.102194</td>\n",
       "      <td>0.003487</td>\n",
       "      <td>0.013799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>0.844946</td>\n",
       "      <td>0.838308</td>\n",
       "      <td>0.928445</td>\n",
       "      <td>0.567107</td>\n",
       "      <td>0.888940</td>\n",
       "      <td>0.813549</td>\n",
       "      <td>0.127450</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.141392</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.017799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>0.855746</td>\n",
       "      <td>0.842988</td>\n",
       "      <td>0.945119</td>\n",
       "      <td>0.490226</td>\n",
       "      <td>0.951299</td>\n",
       "      <td>0.817076</td>\n",
       "      <td>0.169357</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.183189</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.022398</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>0.844631</td>\n",
       "      <td>0.849800</td>\n",
       "      <td>0.932546</td>\n",
       "      <td>0.665086</td>\n",
       "      <td>0.938967</td>\n",
       "      <td>0.846206</td>\n",
       "      <td>0.098873</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.236586</td>\n",
       "      <td>0.011842</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>0.001356</td>\n",
       "      <td>0.5</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.5, 'loss': 'exponential', ...</td>\n",
       "      <td>0.847090</td>\n",
       "      <td>0.856935</td>\n",
       "      <td>0.894812</td>\n",
       "      <td>0.678998</td>\n",
       "      <td>0.917124</td>\n",
       "      <td>0.838992</td>\n",
       "      <td>0.083912</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.055593</td>\n",
       "      <td>0.005162</td>\n",
       "      <td>0.010999</td>\n",
       "      <td>0.000633</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.874634</td>\n",
       "      <td>0.855708</td>\n",
       "      <td>0.937027</td>\n",
       "      <td>0.446143</td>\n",
       "      <td>0.861494</td>\n",
       "      <td>0.795001</td>\n",
       "      <td>0.176817</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.099794</td>\n",
       "      <td>0.004874</td>\n",
       "      <td>0.016399</td>\n",
       "      <td>0.001960</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.820041</td>\n",
       "      <td>0.843022</td>\n",
       "      <td>0.927548</td>\n",
       "      <td>0.683150</td>\n",
       "      <td>0.868223</td>\n",
       "      <td>0.828397</td>\n",
       "      <td>0.080990</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.142391</td>\n",
       "      <td>0.003382</td>\n",
       "      <td>0.018999</td>\n",
       "      <td>0.002607</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.828651</td>\n",
       "      <td>0.856059</td>\n",
       "      <td>0.937460</td>\n",
       "      <td>0.793353</td>\n",
       "      <td>0.895821</td>\n",
       "      <td>0.862269</td>\n",
       "      <td>0.050393</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.187988</td>\n",
       "      <td>0.005830</td>\n",
       "      <td>0.020799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.853525</td>\n",
       "      <td>0.855427</td>\n",
       "      <td>0.897475</td>\n",
       "      <td>0.655569</td>\n",
       "      <td>0.939095</td>\n",
       "      <td>0.840218</td>\n",
       "      <td>0.097528</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.225787</td>\n",
       "      <td>0.004875</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>0.7</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.844794</td>\n",
       "      <td>0.847746</td>\n",
       "      <td>0.931252</td>\n",
       "      <td>0.483110</td>\n",
       "      <td>0.935393</td>\n",
       "      <td>0.808459</td>\n",
       "      <td>0.167276</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.054197</td>\n",
       "      <td>0.004445</td>\n",
       "      <td>0.012599</td>\n",
       "      <td>0.002870</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.826705</td>\n",
       "      <td>0.827138</td>\n",
       "      <td>0.901946</td>\n",
       "      <td>0.572449</td>\n",
       "      <td>0.914576</td>\n",
       "      <td>0.808563</td>\n",
       "      <td>0.123599</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.098194</td>\n",
       "      <td>0.003429</td>\n",
       "      <td>0.015400</td>\n",
       "      <td>0.001200</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.838590</td>\n",
       "      <td>0.840576</td>\n",
       "      <td>0.904780</td>\n",
       "      <td>0.629334</td>\n",
       "      <td>0.905508</td>\n",
       "      <td>0.823758</td>\n",
       "      <td>0.101539</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.142011</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.017180</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.855815</td>\n",
       "      <td>0.861542</td>\n",
       "      <td>0.933795</td>\n",
       "      <td>0.477482</td>\n",
       "      <td>0.918217</td>\n",
       "      <td>0.809370</td>\n",
       "      <td>0.168735</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.182789</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.022999</td>\n",
       "      <td>0.002367</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.859765</td>\n",
       "      <td>0.899012</td>\n",
       "      <td>0.939039</td>\n",
       "      <td>0.686404</td>\n",
       "      <td>0.914320</td>\n",
       "      <td>0.859708</td>\n",
       "      <td>0.090394</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.226787</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.025815</td>\n",
       "      <td>0.002229</td>\n",
       "      <td>0.7</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.864029</td>\n",
       "      <td>0.859463</td>\n",
       "      <td>0.925920</td>\n",
       "      <td>0.765901</td>\n",
       "      <td>0.924032</td>\n",
       "      <td>0.867869</td>\n",
       "      <td>0.058322</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.053823</td>\n",
       "      <td>0.003605</td>\n",
       "      <td>0.010772</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>0.867164</td>\n",
       "      <td>0.903786</td>\n",
       "      <td>0.913757</td>\n",
       "      <td>0.609576</td>\n",
       "      <td>0.927285</td>\n",
       "      <td>0.844314</td>\n",
       "      <td>0.119053</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.098194</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>0.014799</td>\n",
       "      <td>0.001720</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>0.742625</td>\n",
       "      <td>0.864906</td>\n",
       "      <td>0.880642</td>\n",
       "      <td>0.640240</td>\n",
       "      <td>0.941187</td>\n",
       "      <td>0.813920</td>\n",
       "      <td>0.108163</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.141191</td>\n",
       "      <td>0.003060</td>\n",
       "      <td>0.020199</td>\n",
       "      <td>0.002039</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>0.822957</td>\n",
       "      <td>0.847063</td>\n",
       "      <td>0.922406</td>\n",
       "      <td>0.635863</td>\n",
       "      <td>0.915448</td>\n",
       "      <td>0.828747</td>\n",
       "      <td>0.103790</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.186787</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.022599</td>\n",
       "      <td>0.002244</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>0.895839</td>\n",
       "      <td>0.853861</td>\n",
       "      <td>0.911627</td>\n",
       "      <td>0.639823</td>\n",
       "      <td>0.895552</td>\n",
       "      <td>0.839340</td>\n",
       "      <td>0.101583</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.242184</td>\n",
       "      <td>0.002926</td>\n",
       "      <td>0.027398</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.7</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 0.7, 'loss': 'exponential', ...</td>\n",
       "      <td>0.854958</td>\n",
       "      <td>0.851794</td>\n",
       "      <td>0.926450</td>\n",
       "      <td>0.704524</td>\n",
       "      <td>0.949648</td>\n",
       "      <td>0.857475</td>\n",
       "      <td>0.085657</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.056997</td>\n",
       "      <td>0.005899</td>\n",
       "      <td>0.011999</td>\n",
       "      <td>0.001096</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.740376</td>\n",
       "      <td>0.854453</td>\n",
       "      <td>0.932241</td>\n",
       "      <td>0.696217</td>\n",
       "      <td>0.918314</td>\n",
       "      <td>0.828320</td>\n",
       "      <td>0.094622</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.099594</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.014800</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.796171</td>\n",
       "      <td>0.847049</td>\n",
       "      <td>0.935415</td>\n",
       "      <td>0.691039</td>\n",
       "      <td>0.944623</td>\n",
       "      <td>0.842860</td>\n",
       "      <td>0.093989</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.134992</td>\n",
       "      <td>0.026327</td>\n",
       "      <td>0.018599</td>\n",
       "      <td>0.004176</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.789800</td>\n",
       "      <td>0.861627</td>\n",
       "      <td>0.922455</td>\n",
       "      <td>0.699194</td>\n",
       "      <td>0.914356</td>\n",
       "      <td>0.837486</td>\n",
       "      <td>0.083797</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.183988</td>\n",
       "      <td>0.006033</td>\n",
       "      <td>0.022199</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.838665</td>\n",
       "      <td>0.851329</td>\n",
       "      <td>0.931522</td>\n",
       "      <td>0.610056</td>\n",
       "      <td>0.947868</td>\n",
       "      <td>0.835888</td>\n",
       "      <td>0.120774</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.224987</td>\n",
       "      <td>0.003287</td>\n",
       "      <td>0.025398</td>\n",
       "      <td>0.001496</td>\n",
       "      <td>1.0</td>\n",
       "      <td>linear</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'linear', 'n_es...</td>\n",
       "      <td>0.851792</td>\n",
       "      <td>0.870102</td>\n",
       "      <td>0.930423</td>\n",
       "      <td>0.745309</td>\n",
       "      <td>0.917703</td>\n",
       "      <td>0.863066</td>\n",
       "      <td>0.065674</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.053398</td>\n",
       "      <td>0.001959</td>\n",
       "      <td>0.011399</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.767146</td>\n",
       "      <td>0.879525</td>\n",
       "      <td>0.858427</td>\n",
       "      <td>0.713057</td>\n",
       "      <td>0.951644</td>\n",
       "      <td>0.833960</td>\n",
       "      <td>0.084387</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.103993</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.016599</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.858159</td>\n",
       "      <td>0.877826</td>\n",
       "      <td>0.890064</td>\n",
       "      <td>0.698780</td>\n",
       "      <td>0.947673</td>\n",
       "      <td>0.854500</td>\n",
       "      <td>0.083369</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.173590</td>\n",
       "      <td>0.026940</td>\n",
       "      <td>0.018199</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.852563</td>\n",
       "      <td>0.887240</td>\n",
       "      <td>0.938659</td>\n",
       "      <td>0.713836</td>\n",
       "      <td>0.922947</td>\n",
       "      <td>0.863049</td>\n",
       "      <td>0.080330</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.195388</td>\n",
       "      <td>0.010782</td>\n",
       "      <td>0.021798</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.876998</td>\n",
       "      <td>0.880912</td>\n",
       "      <td>0.918143</td>\n",
       "      <td>0.577854</td>\n",
       "      <td>0.918345</td>\n",
       "      <td>0.834450</td>\n",
       "      <td>0.129502</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.229986</td>\n",
       "      <td>0.010825</td>\n",
       "      <td>0.024799</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>square</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'square', 'n_es...</td>\n",
       "      <td>0.810353</td>\n",
       "      <td>0.885550</td>\n",
       "      <td>0.919972</td>\n",
       "      <td>0.577056</td>\n",
       "      <td>0.956448</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.135305</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.003498</td>\n",
       "      <td>0.011199</td>\n",
       "      <td>0.000749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>10</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.823012</td>\n",
       "      <td>0.931465</td>\n",
       "      <td>0.529072</td>\n",
       "      <td>0.887750</td>\n",
       "      <td>0.802721</td>\n",
       "      <td>0.141893</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.100394</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.015199</td>\n",
       "      <td>0.000980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>20</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>0.825896</td>\n",
       "      <td>0.894719</td>\n",
       "      <td>0.901632</td>\n",
       "      <td>0.652611</td>\n",
       "      <td>0.926901</td>\n",
       "      <td>0.840352</td>\n",
       "      <td>0.099657</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.147391</td>\n",
       "      <td>0.004543</td>\n",
       "      <td>0.018200</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>30</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>0.866824</td>\n",
       "      <td>0.858405</td>\n",
       "      <td>0.918279</td>\n",
       "      <td>0.720329</td>\n",
       "      <td>0.939612</td>\n",
       "      <td>0.860690</td>\n",
       "      <td>0.076536</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.190388</td>\n",
       "      <td>0.004587</td>\n",
       "      <td>0.021799</td>\n",
       "      <td>0.000748</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>40</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>0.850954</td>\n",
       "      <td>0.861297</td>\n",
       "      <td>0.884085</td>\n",
       "      <td>0.626966</td>\n",
       "      <td>0.945147</td>\n",
       "      <td>0.833690</td>\n",
       "      <td>0.108404</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.220987</td>\n",
       "      <td>0.009653</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>1.0</td>\n",
       "      <td>exponential</td>\n",
       "      <td>50</td>\n",
       "      <td>{'learning_rate': 1.0, 'loss': 'exponential', ...</td>\n",
       "      <td>0.853749</td>\n",
       "      <td>0.862000</td>\n",
       "      <td>0.930565</td>\n",
       "      <td>0.647526</td>\n",
       "      <td>0.946825</td>\n",
       "      <td>0.848133</td>\n",
       "      <td>0.106773</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0        0.066996      0.003950         0.013398        0.002060   \n",
       "1        0.109393      0.003823         0.015400        0.001855   \n",
       "2        0.154390      0.004497         0.019199        0.001470   \n",
       "3        0.221186      0.034363         0.029999        0.006723   \n",
       "4        0.277983      0.035975         0.026611        0.001483   \n",
       "5        0.058489      0.003140         0.012707        0.002591   \n",
       "6        0.100510      0.004494         0.014496        0.000436   \n",
       "7        0.137991      0.003346         0.018484        0.001341   \n",
       "8        0.208005      0.015002         0.020981        0.000915   \n",
       "9        0.225386      0.003382         0.025598        0.001356   \n",
       "10       0.056410      0.003915         0.012385        0.001038   \n",
       "11       0.102194      0.003487         0.013799        0.000400   \n",
       "12       0.141392      0.002576         0.017799        0.000400   \n",
       "13       0.183189      0.002926         0.022398        0.001357   \n",
       "14       0.236586      0.011842         0.025398        0.001356   \n",
       "15       0.055593      0.005162         0.010999        0.000633   \n",
       "16       0.099794      0.004874         0.016399        0.001960   \n",
       "17       0.142391      0.003382         0.018999        0.002607   \n",
       "18       0.187988      0.005830         0.020799        0.000400   \n",
       "19       0.225787      0.004875         0.025398        0.001855   \n",
       "20       0.054197      0.004445         0.012599        0.002870   \n",
       "21       0.098194      0.003429         0.015400        0.001200   \n",
       "22       0.142011      0.002770         0.017180        0.000410   \n",
       "23       0.182789      0.002039         0.022999        0.002367   \n",
       "24       0.226787      0.005035         0.025815        0.002229   \n",
       "25       0.053823      0.003605         0.010772        0.000387   \n",
       "26       0.098194      0.001600         0.014799        0.001720   \n",
       "27       0.141191      0.003060         0.020199        0.002039   \n",
       "28       0.186787      0.002926         0.022599        0.002244   \n",
       "29       0.242184      0.002926         0.027398        0.002059   \n",
       "30       0.056997      0.005899         0.011999        0.001096   \n",
       "31       0.099594      0.004317         0.014800        0.001166   \n",
       "32       0.134992      0.026327         0.018599        0.004176   \n",
       "33       0.183988      0.006033         0.022199        0.001470   \n",
       "34       0.224987      0.003287         0.025398        0.001496   \n",
       "35       0.053398      0.001959         0.011399        0.000489   \n",
       "36       0.103993      0.005621         0.016599        0.002417   \n",
       "37       0.173590      0.026940         0.018199        0.001166   \n",
       "38       0.195388      0.010782         0.021798        0.000748   \n",
       "39       0.229986      0.010825         0.024799        0.000400   \n",
       "40       0.054397      0.003498         0.011199        0.000749   \n",
       "41       0.100394      0.002059         0.015199        0.000980   \n",
       "42       0.147391      0.004543         0.018200        0.000400   \n",
       "43       0.190388      0.004587         0.021799        0.000748   \n",
       "44       0.220987      0.009653         0.023599        0.004031   \n",
       "\n",
       "    param_learning_rate   param_loss  param_n_estimators  \\\n",
       "0                   0.5       linear                  10   \n",
       "1                   0.5       linear                  20   \n",
       "2                   0.5       linear                  30   \n",
       "3                   0.5       linear                  40   \n",
       "4                   0.5       linear                  50   \n",
       "5                   0.5       square                  10   \n",
       "6                   0.5       square                  20   \n",
       "7                   0.5       square                  30   \n",
       "8                   0.5       square                  40   \n",
       "9                   0.5       square                  50   \n",
       "10                  0.5  exponential                  10   \n",
       "11                  0.5  exponential                  20   \n",
       "12                  0.5  exponential                  30   \n",
       "13                  0.5  exponential                  40   \n",
       "14                  0.5  exponential                  50   \n",
       "15                  0.7       linear                  10   \n",
       "16                  0.7       linear                  20   \n",
       "17                  0.7       linear                  30   \n",
       "18                  0.7       linear                  40   \n",
       "19                  0.7       linear                  50   \n",
       "20                  0.7       square                  10   \n",
       "21                  0.7       square                  20   \n",
       "22                  0.7       square                  30   \n",
       "23                  0.7       square                  40   \n",
       "24                  0.7       square                  50   \n",
       "25                  0.7  exponential                  10   \n",
       "26                  0.7  exponential                  20   \n",
       "27                  0.7  exponential                  30   \n",
       "28                  0.7  exponential                  40   \n",
       "29                  0.7  exponential                  50   \n",
       "30                  1.0       linear                  10   \n",
       "31                  1.0       linear                  20   \n",
       "32                  1.0       linear                  30   \n",
       "33                  1.0       linear                  40   \n",
       "34                  1.0       linear                  50   \n",
       "35                  1.0       square                  10   \n",
       "36                  1.0       square                  20   \n",
       "37                  1.0       square                  30   \n",
       "38                  1.0       square                  40   \n",
       "39                  1.0       square                  50   \n",
       "40                  1.0  exponential                  10   \n",
       "41                  1.0  exponential                  20   \n",
       "42                  1.0  exponential                  30   \n",
       "43                  1.0  exponential                  40   \n",
       "44                  1.0  exponential                  50   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...           0.812028   \n",
       "1   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...           0.844804   \n",
       "2   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...           0.853675   \n",
       "3   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...           0.848865   \n",
       "4   {'learning_rate': 0.5, 'loss': 'linear', 'n_es...           0.857616   \n",
       "5   {'learning_rate': 0.5, 'loss': 'square', 'n_es...           0.869898   \n",
       "6   {'learning_rate': 0.5, 'loss': 'square', 'n_es...           0.835265   \n",
       "7   {'learning_rate': 0.5, 'loss': 'square', 'n_es...           0.848227   \n",
       "8   {'learning_rate': 0.5, 'loss': 'square', 'n_es...           0.829661   \n",
       "9   {'learning_rate': 0.5, 'loss': 'square', 'n_es...           0.865297   \n",
       "10  {'learning_rate': 0.5, 'loss': 'exponential', ...           0.866928   \n",
       "11  {'learning_rate': 0.5, 'loss': 'exponential', ...           0.844946   \n",
       "12  {'learning_rate': 0.5, 'loss': 'exponential', ...           0.855746   \n",
       "13  {'learning_rate': 0.5, 'loss': 'exponential', ...           0.844631   \n",
       "14  {'learning_rate': 0.5, 'loss': 'exponential', ...           0.847090   \n",
       "15  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...           0.874634   \n",
       "16  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...           0.820041   \n",
       "17  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...           0.828651   \n",
       "18  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...           0.853525   \n",
       "19  {'learning_rate': 0.7, 'loss': 'linear', 'n_es...           0.844794   \n",
       "20  {'learning_rate': 0.7, 'loss': 'square', 'n_es...           0.826705   \n",
       "21  {'learning_rate': 0.7, 'loss': 'square', 'n_es...           0.838590   \n",
       "22  {'learning_rate': 0.7, 'loss': 'square', 'n_es...           0.855815   \n",
       "23  {'learning_rate': 0.7, 'loss': 'square', 'n_es...           0.859765   \n",
       "24  {'learning_rate': 0.7, 'loss': 'square', 'n_es...           0.864029   \n",
       "25  {'learning_rate': 0.7, 'loss': 'exponential', ...           0.867164   \n",
       "26  {'learning_rate': 0.7, 'loss': 'exponential', ...           0.742625   \n",
       "27  {'learning_rate': 0.7, 'loss': 'exponential', ...           0.822957   \n",
       "28  {'learning_rate': 0.7, 'loss': 'exponential', ...           0.895839   \n",
       "29  {'learning_rate': 0.7, 'loss': 'exponential', ...           0.854958   \n",
       "30  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...           0.740376   \n",
       "31  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...           0.796171   \n",
       "32  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...           0.789800   \n",
       "33  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...           0.838665   \n",
       "34  {'learning_rate': 1.0, 'loss': 'linear', 'n_es...           0.851792   \n",
       "35  {'learning_rate': 1.0, 'loss': 'square', 'n_es...           0.767146   \n",
       "36  {'learning_rate': 1.0, 'loss': 'square', 'n_es...           0.858159   \n",
       "37  {'learning_rate': 1.0, 'loss': 'square', 'n_es...           0.852563   \n",
       "38  {'learning_rate': 1.0, 'loss': 'square', 'n_es...           0.876998   \n",
       "39  {'learning_rate': 1.0, 'loss': 'square', 'n_es...           0.810353   \n",
       "40  {'learning_rate': 1.0, 'loss': 'exponential', ...           0.842308   \n",
       "41  {'learning_rate': 1.0, 'loss': 'exponential', ...           0.825896   \n",
       "42  {'learning_rate': 1.0, 'loss': 'exponential', ...           0.866824   \n",
       "43  {'learning_rate': 1.0, 'loss': 'exponential', ...           0.850954   \n",
       "44  {'learning_rate': 1.0, 'loss': 'exponential', ...           0.853749   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.831411           0.942565           0.254487   \n",
       "1            0.853377           0.868303           0.510321   \n",
       "2            0.870686           0.920620           0.627491   \n",
       "3            0.845650           0.924003           0.505331   \n",
       "4            0.847949           0.882702           0.652201   \n",
       "5            0.832227           0.928592           0.361927   \n",
       "6            0.864903           0.894649           0.551666   \n",
       "7            0.857201           0.887180           0.728114   \n",
       "8            0.871101           0.935403           0.621213   \n",
       "9            0.862240           0.924194           0.612427   \n",
       "10           0.830406           0.853591           0.600606   \n",
       "11           0.838308           0.928445           0.567107   \n",
       "12           0.842988           0.945119           0.490226   \n",
       "13           0.849800           0.932546           0.665086   \n",
       "14           0.856935           0.894812           0.678998   \n",
       "15           0.855708           0.937027           0.446143   \n",
       "16           0.843022           0.927548           0.683150   \n",
       "17           0.856059           0.937460           0.793353   \n",
       "18           0.855427           0.897475           0.655569   \n",
       "19           0.847746           0.931252           0.483110   \n",
       "20           0.827138           0.901946           0.572449   \n",
       "21           0.840576           0.904780           0.629334   \n",
       "22           0.861542           0.933795           0.477482   \n",
       "23           0.899012           0.939039           0.686404   \n",
       "24           0.859463           0.925920           0.765901   \n",
       "25           0.903786           0.913757           0.609576   \n",
       "26           0.864906           0.880642           0.640240   \n",
       "27           0.847063           0.922406           0.635863   \n",
       "28           0.853861           0.911627           0.639823   \n",
       "29           0.851794           0.926450           0.704524   \n",
       "30           0.854453           0.932241           0.696217   \n",
       "31           0.847049           0.935415           0.691039   \n",
       "32           0.861627           0.922455           0.699194   \n",
       "33           0.851329           0.931522           0.610056   \n",
       "34           0.870102           0.930423           0.745309   \n",
       "35           0.879525           0.858427           0.713057   \n",
       "36           0.877826           0.890064           0.698780   \n",
       "37           0.887240           0.938659           0.713836   \n",
       "38           0.880912           0.918143           0.577854   \n",
       "39           0.885550           0.919972           0.577056   \n",
       "40           0.823012           0.931465           0.529072   \n",
       "41           0.894719           0.901632           0.652611   \n",
       "42           0.858405           0.918279           0.720329   \n",
       "43           0.861297           0.884085           0.626966   \n",
       "44           0.862000           0.930565           0.647526   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.871159         0.742330        0.247982               45  \n",
       "1            0.917731         0.798907        0.146485               42  \n",
       "2            0.914556         0.837405        0.107994               19  \n",
       "3            0.916376         0.808045        0.154854               39  \n",
       "4            0.942776         0.836649        0.097951               21  \n",
       "5            0.940197         0.786568        0.215927               44  \n",
       "6            0.911107         0.811518        0.132488               35  \n",
       "7            0.917535         0.847651        0.064540               10  \n",
       "8            0.919646         0.835405        0.113385               23  \n",
       "9            0.921207         0.837073        0.115382               20  \n",
       "10           0.882484         0.806803        0.104505               40  \n",
       "11           0.888940         0.813549        0.127450               34  \n",
       "12           0.951299         0.817076        0.169357               32  \n",
       "13           0.938967         0.846206        0.098873               11  \n",
       "14           0.917124         0.838992        0.083912               17  \n",
       "15           0.861494         0.795001        0.176817               43  \n",
       "16           0.868223         0.828397        0.080990               29  \n",
       "17           0.895821         0.862269        0.050393                4  \n",
       "18           0.939095         0.840218        0.097528               15  \n",
       "19           0.935393         0.808459        0.167276               38  \n",
       "20           0.914576         0.808563        0.123599               37  \n",
       "21           0.905508         0.823758        0.101539               31  \n",
       "22           0.918217         0.809370        0.168735               36  \n",
       "23           0.914320         0.859708        0.090394                6  \n",
       "24           0.924032         0.867869        0.058322                1  \n",
       "25           0.927285         0.844314        0.119053               12  \n",
       "26           0.941187         0.813920        0.108163               33  \n",
       "27           0.915448         0.828747        0.103790               28  \n",
       "28           0.895552         0.839340        0.101583               16  \n",
       "29           0.949648         0.857475        0.085657                7  \n",
       "30           0.918314         0.828320        0.094622               30  \n",
       "31           0.944623         0.842860        0.093989               13  \n",
       "32           0.914356         0.837486        0.083797               18  \n",
       "33           0.947868         0.835888        0.120774               22  \n",
       "34           0.917703         0.863066        0.065674                2  \n",
       "35           0.951644         0.833960        0.084387               25  \n",
       "36           0.947673         0.854500        0.083369                8  \n",
       "37           0.922947         0.863049        0.080330                3  \n",
       "38           0.918345         0.834450        0.129502               24  \n",
       "39           0.956448         0.829876        0.135305               27  \n",
       "40           0.887750         0.802721        0.141893               41  \n",
       "41           0.926901         0.840352        0.099657               14  \n",
       "42           0.939612         0.860690        0.076536                5  \n",
       "43           0.945147         0.833690        0.108404               26  \n",
       "44           0.946825         0.848133        0.106773                9  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table = pd.DataFrame.from_dict(re)\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6c6341-9731-4a2d-bd5e-86c9134bc347",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_spend = float(input(\"Enter R&D spend value:\"))\n",
    "admin_value = float(input(\"Enter Administration spend:\"))\n",
    "marketing_spend = float(input(\"Enter Marketing spend:\"))\n",
    "state_input1 = int(input(\"Enter 0 or 1 for State_florida:\"))\n",
    "state_input2 = int(input(\"Enter 0 or 1 for State_newYork:\"))\n",
    "Future_prediction=.predict([[rd_spend,admin_value,marketing_spend,state_input1,state_input2]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
